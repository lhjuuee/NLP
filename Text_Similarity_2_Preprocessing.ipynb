{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Similarity with Quora question pair\n",
    "## Preprocessing\n",
    "### 1. Data \n",
    "#### 1.1 Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style='dark')\n",
    "\n",
    "import re\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_PATH = \"C:/python/NLP/Chap_5/\"\n",
    "TRAIN_FILE = \"train.csv\"\n",
    "\n",
    "train = pd.read_csv(DATA_PATH + TRAIN_FILE, encoding='UTF-8')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 404290 entries, 0 to 404289\n",
      "Data columns (total 6 columns):\n",
      "id              404290 non-null int64\n",
      "qid1            404290 non-null int64\n",
      "qid2            404290 non-null int64\n",
      "question1       404289 non-null object\n",
      "question2       404288 non-null object\n",
      "is_duplicate    404290 non-null int64\n",
      "dtypes: int64(4), object(2)\n",
      "memory usage: 18.5+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Data sampling \n",
    "##### Ease difficulty from imbalanced data  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5852831268846044\n"
     ]
    }
   ],
   "source": [
    "train_pos_data = train.loc[train['is_duplicate'] == 1]\n",
    "train_neg_data = train.loc[train['is_duplicate'] == 0]\n",
    "\n",
    "class_difference = len(train_neg_data) - len(train_pos_data)\n",
    "sample_frac = 1 - (class_difference / len(train_neg_data))\n",
    "\n",
    "train_neg_data = train_neg_data.sample(frac = sample_frac)\n",
    "print(sample_frac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated: 149263\n",
      "Not duplicated: 149263\n"
     ]
    }
   ],
   "source": [
    "print(\"Duplicated: {}\".format(len(train_pos_data)))\n",
    "print(\"Not duplicated: {}\".format(len(train_neg_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 298526 entries, 5 to 197611\n",
      "Data columns (total 6 columns):\n",
      "id              298526 non-null int64\n",
      "qid1            298526 non-null int64\n",
      "qid2            298526 non-null int64\n",
      "question1       298526 non-null object\n",
      "question2       298524 non-null object\n",
      "is_duplicate    298526 non-null int64\n",
      "dtypes: int64(4), object(2)\n",
      "memory usage: 15.9+ MB\n"
     ]
    }
   ],
   "source": [
    "train = pd.concat([train_pos_data, train_neg_data])\n",
    "train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILTERS = '[^a-zA-Z0-9]'              # Including number\n",
    "change_filter = re.compile(FILTERS)\n",
    "\n",
    "question1 = [str(s) for s in train['question1']]\n",
    "quesiton2 = [str(s) for s in train['question2']]\n",
    "\n",
    "re_question1 = []\n",
    "re_question2 = []\n",
    "\n",
    "for q in question1:\n",
    "    re_question1.append(re.sub(change_filter, ' ', q).lower())\n",
    "for q in quesiton2:    \n",
    "    re_question2.append(re.sub(change_filter, ' ', q).lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(re_question1 + re_question2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "question1_sequence = tokenizer.texts_to_sequences(re_question1)\n",
    "question2_sequence = tokenizer.texts_to_sequences(re_question2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2123, 5, 81, 7, 9343, 950, 4371, 778, 12, 4371, 5787, 2, 21, 29, 259, 49, 66]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question1_sequence[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 31\n",
    "\n",
    "q1_data = pad_sequences(question1_sequence, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
    "q2_data = pad_sequences(question2_sequence, maxlen=MAX_SEQUENCE_LENGTH, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Save\n",
    "##### For train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of question1_data: (298526, 31)\n",
      "Shape of question2_data: (298526, 31)\n",
      "Shape of Label: (298526,)\n",
      "Word index: 69263\n"
     ]
    }
   ],
   "source": [
    "word_vocab={}\n",
    "word_vocab = tokenizer.word_index\n",
    "\n",
    "labels = np.array(train['is_duplicate'], dtype=int)\n",
    "\n",
    "print('Shape of question1_data: {}'.format(q1_data.shape))\n",
    "print('Shape of question2_data: {}'.format(q2_data.shape))\n",
    "print('Shape of Label: {}'.format(labels.shape))\n",
    "print('Word index: %d' %(len(word_vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "data_configs = {}\n",
    "data_configs['vocab'] = word_vocab\n",
    "data_configs['vocab_size'] = len(word_vocab) + 1\n",
    "\n",
    "TRAIN_Q1 = 'q1_train.npy'\n",
    "TRAIN_Q2 = 'q2_train.npy'\n",
    "TRAIN_LABEL = 'label_train.npy'\n",
    "DATA_CONFIGS = 'data_configs.npy'\n",
    "\n",
    "if not os.path.exists(DATA_PATH + \"data_for_modeling\"):\n",
    "    os.mkdir(DATA_PATH + \"data_for_modeling\")\n",
    "    \n",
    "np.save(open(DATA_PATH + \"data_for_modeling/\" + TRAIN_Q1, 'wb'), q1_data)\n",
    "np.save(open(DATA_PATH + \"data_for_modeling/\" + TRAIN_Q2, 'wb'), q2_data)\n",
    "np.save(open(DATA_PATH + \"data_for_modeling/\" + TRAIN_LABEL, 'wb'), labels)\n",
    "json.dump(data_configs, open(DATA_PATH + \"data_for_modeling/\" + DATA_CONFIGS, 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(DATA_PATH + 'test.csv', encoding='utf-8')\n",
    "valid_ids = [type(x) == int for x in test_data.test_id]\n",
    "test_data = test_data[valid_ids].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILTERS = '[^a-zA-Z0-9]'              # Including number\n",
    "change_filter = re.compile(FILTERS)\n",
    "\n",
    "test_question1 = [str(s) for s in test_data['question1']]\n",
    "test_quesiton2 = [str(s) for s in test_data['question2']]\n",
    "\n",
    "test_re_question1 = []\n",
    "test_re_question2 = []\n",
    "\n",
    "for q in test_question1:\n",
    "    test_re_question1.append(re.sub(change_filter, ' ', q).lower())\n",
    "for q in test_quesiton2:    \n",
    "    test_re_question2.append(re.sub(change_filter, ' ', q).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_question1_sequence = tokenizer.texts_to_sequences(test_re_question1)\n",
    "test_question2_sequence = tokenizer.texts_to_sequences(test_re_question2)\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 31\n",
    "\n",
    "test_q1_data = pad_sequences(test_question1_sequence, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
    "test_q2_data = pad_sequences(test_question2_sequence, maxlen=MAX_SEQUENCE_LENGTH, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of test_question1_data: (2345796, 31)\n",
      "Shape of test_question2_data: (2345796, 31)\n",
      "Shape of test_id: (2345796,)\n"
     ]
    }
   ],
   "source": [
    "test_id = np.array(test_data['test_id'])\n",
    "\n",
    "print('Shape of test_question1_data: {}'.format(test_q1_data.shape))\n",
    "print('Shape of test_question2_data: {}'.format(test_q2_data.shape))\n",
    "print('Shape of test_id: {}'.format(test_id.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_Q1 = 'test_q1.npy'\n",
    "TEST_Q2 = 'test_q2.npy'\n",
    "TEST_ID = 'test_id.npy'\n",
    "\n",
    "np.save(open(DATA_PATH + TEST_Q1, 'wb'), test_q1_data)\n",
    "np.save(open(DATA_PATH + TEST_Q2, 'wb'), test_q2_data)\n",
    "np.save(open(DATA_PATH + TEST_ID, 'wb'), test_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Note\n",
    "\n",
    "* MAX LENGTH\n",
    "\n",
    "EDA과정에서 도출된 의사결정. 로그 스케일 말고 다른 값으로 보자\n",
    "\n",
    "* 정규화\n",
    "\n",
    "숫자 포함 or 제외?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
