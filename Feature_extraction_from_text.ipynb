{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction from text with scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In text, feature extraction means digitizing. I am going to look two method to do this.\n",
    "\n",
    "**CountVectorizer, TfidVectorizer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. CountVectorizer\n",
    "\n",
    "1. First, it needs to be fit with texts to make vocabulary dictionary. (or character)\n",
    "2. And it counts number of word in text for each data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'나는': 3, '배가': 7, '고프다': 0, '내일': 4, '점심': 8, '뭐먹지': 6, '공부': 1, '해야겠다': 9, '먹고': 5, '공부해야지': 2}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "text_data = ['나는 배가 고프다',\n",
    "             '내일 점심 뭐먹지',\n",
    "             '내일 공부 해야겠다',\n",
    "             '점심 먹고 공부해야지']\n",
    "\n",
    "count_vectorizer = CountVectorizer()\n",
    "count_vectorizer.fit(text_data)\n",
    "print(count_vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It makes index for each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 1 0 0 0 1 0 0]]\n"
     ]
    }
   ],
   "source": [
    "sentence = [text_data[0]]\n",
    "print(count_vectorizer.transform(sentence).toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And it finally counts number of words. It is considered as very simple method to vectorize. It doesn't consider importance of each word.\n",
    "\n",
    "TF-IDF method is better method to solve this problem.\n",
    "\n",
    "### 2. TF-IDF, TfidVectorizer\n",
    "\n",
    "It extracts feature from text according to specific value. Simply, TF(Term Frequency) means number of appearance, one word in a data\n",
    "\n",
    "and DF(Document Frequency) also means number of appearance, but one word in all data. IDF(Inverse Document Frequency) is calculated with \n",
    "\n",
    "inverse of DF value which means its value would increase if it doesn't appear frequently\n",
    "\n",
    "**TFIDF** is value of multiplying TF and IDF. It has large value if specific word has high frequency in a data and low frequency in all data.\n",
    "\n",
    "So, it can deal with postposition or demonstrative pronoun which is not that important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'나는': 3, '배가': 7, '고프다': 0, '내일': 4, '점심': 8, '뭐먹지': 6, '공부': 1, '해야겠다': 9, '먹고': 5, '공부해야지': 2}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_vectorizer.fit(text_data)\n",
    "print(tfidf_vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.57735027 0.         0.         0.57735027 0.         0.\n",
      "  0.         0.57735027 0.         0.        ]\n",
      " [0.         0.         0.         0.         0.52640543 0.\n",
      "  0.66767854 0.         0.52640543 0.        ]\n",
      " [0.         0.61761437 0.         0.         0.48693426 0.\n",
      "  0.         0.         0.         0.61761437]\n",
      " [0.         0.         0.61761437 0.         0.         0.61761437\n",
      "  0.         0.         0.48693426 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "sentence = [text_data[0]]\n",
    "print(tfidf_vectorizer.transform(text_data).toarray())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
